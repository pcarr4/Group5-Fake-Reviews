{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Activation,\n",
    "    MaxPooling1D,\n",
    "    Flatten,\n",
    "    Embedding,\n",
    "    Conv1D,\n",
    "    GlobalMaxPooling1D,\n",
    "    BatchNormalization,\n",
    "    CuDNNGRU,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Input,\n",
    "    concatenate,\n",
    ")\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "from numpy import random\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviewContent+metadataBalanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9/8/2014</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/30/2014</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160927</th>\n",
       "      <td>265253</td>\n",
       "      <td>5041</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/15/2011</td>\n",
       "      <td>Great local lounge spot! After work and regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160928</th>\n",
       "      <td>265316</td>\n",
       "      <td>5042</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12/24/2014</td>\n",
       "      <td>I have been to this place for the third time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160929</th>\n",
       "      <td>62901</td>\n",
       "      <td>5043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8/4/2011</td>\n",
       "      <td>Horrible service. I saw a customer accidentall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160930</th>\n",
       "      <td>201246</td>\n",
       "      <td>5043</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4/14/2013</td>\n",
       "      <td>Its your standard late-night drunk filled coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160931</th>\n",
       "      <td>201247</td>\n",
       "      <td>5043</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4/12/2009</td>\n",
       "      <td>If you've ever attended high school in Hamden,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  prod_id  rating  label        date  \\\n",
       "0          5044        0       1      0  11/16/2014   \n",
       "1          5045        0       1      0    9/8/2014   \n",
       "2          5046        0       3      0   10/6/2013   \n",
       "3          5047        0       5      0  11/30/2014   \n",
       "4          5048        0       5      0   8/28/2014   \n",
       "...         ...      ...     ...    ...         ...   \n",
       "160927   265253     5041       5      0  11/15/2011   \n",
       "160928   265316     5042       5      0  12/24/2014   \n",
       "160929    62901     5043       1      0    8/4/2011   \n",
       "160930   201246     5043       2      0   4/14/2013   \n",
       "160931   201247     5043       4      0   4/12/2009   \n",
       "\n",
       "                                                    text_  \n",
       "0       Drinks were bad, the hot chocolate was watered...  \n",
       "1       This was the worst experience I've ever had a ...  \n",
       "2       This is located on the site of the old Spruce ...  \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...  \n",
       "4       I love Toast! The food choices are fantastic -...  \n",
       "...                                                   ...  \n",
       "160927  Great local lounge spot! After work and regula...  \n",
       "160928  I have been to this place for the third time i...  \n",
       "160929  Horrible service. I saw a customer accidentall...  \n",
       "160930  Its your standard late-night drunk filled coll...  \n",
       "160931  If you've ever attended high school in Hamden,...  \n",
       "\n",
       "[160932 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>160932.000000</td>\n",
       "      <td>160932.000000</td>\n",
       "      <td>160932.000000</td>\n",
       "      <td>160932.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>82018.298940</td>\n",
       "      <td>1727.836900</td>\n",
       "      <td>3.834868</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>74370.033461</td>\n",
       "      <td>1559.997545</td>\n",
       "      <td>1.289868</td>\n",
       "      <td>0.500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5044.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23998.750000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51973.500000</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>131655.250000</td>\n",
       "      <td>3122.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>265319.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        prod_id         rating          label\n",
       "count  160932.000000  160932.000000  160932.000000  160932.000000\n",
       "mean    82018.298940    1727.836900       3.834868       0.500000\n",
       "std     74370.033461    1559.997545       1.289868       0.500002\n",
       "min      5044.000000       0.000000       1.000000       0.000000\n",
       "25%     23998.750000     400.000000       3.000000       0.000000\n",
       "50%     51973.500000     963.000000       4.000000       0.500000\n",
       "75%    131655.250000    3122.000000       5.000000       1.000000\n",
       "max    265319.000000    5043.000000       5.000000       1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['prod_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate Maximum Number of Reviews (MNR)\n",
    "def calculate_mnr(df1):\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df1['reviews_per_day'] = df1.groupby(['user_id', df1['date'].dt.date])['user_id'].transform('count')\n",
    "    max_reviews_per_day = df1.groupby('user_id')['reviews_per_day'].max()\n",
    "    return max_reviews_per_day\n",
    "\n",
    "# Function to calculate Percentage of Positive Reviews (PR)\n",
    "def calculate_pr(df1):\n",
    "    # Group reviews by user_id and create a list of reviews for each user\n",
    "    user_reviews = df1.groupby('user_id')['rating'].apply(list).reset_index(name='reviews')\n",
    "\n",
    "    # Calculate the percentage of positive reviews for each user\n",
    "    user_reviews['pr'] = user_reviews['reviews'].apply(\n",
    "        lambda reviews: (\n",
    "            sum(rating in [4, 5] for rating in reviews) / len(reviews)\n",
    "        ) if len(reviews) > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Merge the result back to the original dataframe\n",
    "    pr_df = user_reviews[['user_id', 'pr']]\n",
    "    return pr_df\n",
    "\n",
    "# Function to calculate Review Length (RL)\n",
    "def calculate_rl(df1):\n",
    "    df1['review_length'] = df1['text_'].apply(lambda x: len(x.split()))\n",
    "    avg_review_length = df1.groupby('user_id')['review_length'].mean()\n",
    "    return avg_review_length\n",
    "\n",
    "# Function to calculate Reviewer Deviation (RD)\n",
    "def calculate_rd(df1):\n",
    "    average_ratings_per_product = df1.groupby('prod_id')['rating'].mean()\n",
    "    tempdf = pd.merge(df1, average_ratings_per_product, on='prod_id', how='left')\n",
    "    tempdf['rating_deviation'] = np.abs(tempdf['rating_x'] - tempdf['rating_y'])\n",
    "    average_deviation_per_user = tempdf.groupby('user_id')['rating_deviation'].mean()\n",
    "    return average_deviation_per_user\n",
    "\n",
    "# Function to calculate Maximum Content Similarity (MCS)\n",
    "def calculate_mcs(df1):\n",
    "    # Group by user_id and collect all reviews\n",
    "    user_reviews = df1.groupby('user_id')['text_'].agg(lambda x: list(map(str, x))).reset_index()\n",
    "\n",
    "    # Initialize lists to store user_ids and max similarities\n",
    "    user_ids = []\n",
    "    max_similarities = []\n",
    "    user_reviews_dict = dict(zip(user_reviews['user_id'], user_reviews['text_']))\n",
    "\n",
    "\n",
    "\n",
    "    # Create a TF-IDF vectorizer outside the loop\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    for user_id, reviews in user_reviews_dict.items():\n",
    "        # If there is only one review, similarity is 0\n",
    "        if len(reviews) <= 1:\n",
    "            user_ids.append(user_id)\n",
    "            max_similarities.append(0)\n",
    "        else:\n",
    "            reviews = list(map(str, reviews))\n",
    "\n",
    "            # Calculate TF-IDF vectors and cosine similarity between all pairs of reviews\n",
    "            tfidf_matrix = vectorizer.fit_transform(reviews)\n",
    "            similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "            # Set the diagonal elements to 0 to avoid self-comparison\n",
    "            np.fill_diagonal(similarity_matrix, 0)\n",
    "\n",
    "            # Find the maximum similarity value\n",
    "            max_similarity = np.max(similarity_matrix)\n",
    "            \n",
    "            # Append user_id and corresponding maximum similarity\n",
    "            user_ids.append(user_id)\n",
    "            max_similarities.append(max_similarity)\n",
    "\n",
    "    return pd.DataFrame({'user_id': user_ids, 'mcs': max_similarities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9/8/2014</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/30/2014</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160927</th>\n",
       "      <td>265253</td>\n",
       "      <td>5041</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/15/2011</td>\n",
       "      <td>Great local lounge spot! After work and regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160928</th>\n",
       "      <td>265316</td>\n",
       "      <td>5042</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12/24/2014</td>\n",
       "      <td>I have been to this place for the third time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160929</th>\n",
       "      <td>62901</td>\n",
       "      <td>5043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8/4/2011</td>\n",
       "      <td>Horrible service. I saw a customer accidentall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160930</th>\n",
       "      <td>201246</td>\n",
       "      <td>5043</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4/14/2013</td>\n",
       "      <td>Its your standard late-night drunk filled coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160931</th>\n",
       "      <td>201247</td>\n",
       "      <td>5043</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4/12/2009</td>\n",
       "      <td>If you've ever attended high school in Hamden,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  prod_id  rating  label        date  \\\n",
       "0          5044        0       1      0  11/16/2014   \n",
       "1          5045        0       1      0    9/8/2014   \n",
       "2          5046        0       3      0   10/6/2013   \n",
       "3          5047        0       5      0  11/30/2014   \n",
       "4          5048        0       5      0   8/28/2014   \n",
       "...         ...      ...     ...    ...         ...   \n",
       "160927   265253     5041       5      0  11/15/2011   \n",
       "160928   265316     5042       5      0  12/24/2014   \n",
       "160929    62901     5043       1      0    8/4/2011   \n",
       "160930   201246     5043       2      0   4/14/2013   \n",
       "160931   201247     5043       4      0   4/12/2009   \n",
       "\n",
       "                                                    text_  \n",
       "0       Drinks were bad, the hot chocolate was watered...  \n",
       "1       This was the worst experience I've ever had a ...  \n",
       "2       This is located on the site of the old Spruce ...  \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...  \n",
       "4       I love Toast! The food choices are fantastic -...  \n",
       "...                                                   ...  \n",
       "160927  Great local lounge spot! After work and regula...  \n",
       "160928  I have been to this place for the third time i...  \n",
       "160929  Horrible service. I saw a customer accidentall...  \n",
       "160930  Its your standard late-night drunk filled coll...  \n",
       "160931  If you've ever attended high school in Hamden,...  \n",
       "\n",
       "[160932 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MNR...\n",
      "MNR calculation completed.\n",
      "Calculating PR...\n",
      "PR calculation completed.\n",
      "Calculating RL...\n",
      "RL calculation completed.\n",
      "Calculating RD...\n",
      "RD calculation completed.\n",
      "Calculating MCS...\n",
      "MCS calculation completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Calculating MNR...\")\n",
    "mnr_df = calculate_mnr(copy_df)\n",
    "print(\"MNR calculation completed.\")\n",
    "\n",
    "print(\"Calculating PR...\")\n",
    "pr_df = calculate_pr(copy_df)\n",
    "print(\"PR calculation completed.\")\n",
    "\n",
    "print(\"Calculating RL...\")\n",
    "rl_df = calculate_rl(copy_df)\n",
    "print(\"RL calculation completed.\")\n",
    "\n",
    "print(\"Calculating RD...\")\n",
    "rd_df = calculate_rd(copy_df)\n",
    "print(\"RD calculation completed.\")\n",
    "\n",
    "print(\"Calculating MCS...\")\n",
    "mcs_df = calculate_mcs(copy_df)\n",
    "print(\"MCS calculation completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9/8/2014</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/30/2014</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160927</th>\n",
       "      <td>265253</td>\n",
       "      <td>5041</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/15/2011</td>\n",
       "      <td>Great local lounge spot! After work and regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160928</th>\n",
       "      <td>265316</td>\n",
       "      <td>5042</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12/24/2014</td>\n",
       "      <td>I have been to this place for the third time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160929</th>\n",
       "      <td>62901</td>\n",
       "      <td>5043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8/4/2011</td>\n",
       "      <td>Horrible service. I saw a customer accidentall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160930</th>\n",
       "      <td>201246</td>\n",
       "      <td>5043</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4/14/2013</td>\n",
       "      <td>Its your standard late-night drunk filled coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160931</th>\n",
       "      <td>201247</td>\n",
       "      <td>5043</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4/12/2009</td>\n",
       "      <td>If you've ever attended high school in Hamden,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  prod_id  rating  label        date  \\\n",
       "0          5044        0       1      0  11/16/2014   \n",
       "1          5045        0       1      0    9/8/2014   \n",
       "2          5046        0       3      0   10/6/2013   \n",
       "3          5047        0       5      0  11/30/2014   \n",
       "4          5048        0       5      0   8/28/2014   \n",
       "...         ...      ...     ...    ...         ...   \n",
       "160927   265253     5041       5      0  11/15/2011   \n",
       "160928   265316     5042       5      0  12/24/2014   \n",
       "160929    62901     5043       1      0    8/4/2011   \n",
       "160930   201246     5043       2      0   4/14/2013   \n",
       "160931   201247     5043       4      0   4/12/2009   \n",
       "\n",
       "                                                    text_  \n",
       "0       Drinks were bad, the hot chocolate was watered...  \n",
       "1       This was the worst experience I've ever had a ...  \n",
       "2       This is located on the site of the old Spruce ...  \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...  \n",
       "4       I love Toast! The food choices are fantastic -...  \n",
       "...                                                   ...  \n",
       "160927  Great local lounge spot! After work and regula...  \n",
       "160928  I have been to this place for the third time i...  \n",
       "160929  Horrible service. I saw a customer accidentall...  \n",
       "160930  Its your standard late-night drunk filled coll...  \n",
       "160931  If you've ever attended high school in Hamden,...  \n",
       "\n",
       "[160932 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge the calculated features with the original dataset on 'user_id'\n",
    "df = df.merge(mnr_df, on='user_id', how='left')\n",
    "df = df.merge(pr_df, on='user_id', how='left')\n",
    "df = df.merge(rl_df, on='user_id', how='left')\n",
    "df = df.merge(rd_df, on='user_id', how='left')\n",
    "df = df.merge(mcs_df, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'reviews_per_day': 'maximum_review_per_day_for_user', 'pr': 'percent_postive_reviews_by_user','review_length': 'max_user_review_length','rating_deviation': 'avg_user_rating_deviation_per_product','mcs': 'max_cosine_similarity_to_user_reviews'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>text_</th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.613636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9/8/2014</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>2.613636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>0.723817</td>\n",
       "      <td>0.100917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/30/2014</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>1.386364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>1.386364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160927</th>\n",
       "      <td>265253</td>\n",
       "      <td>5041</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/15/2011</td>\n",
       "      <td>Great local lounge spot! After work and regula...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160928</th>\n",
       "      <td>265316</td>\n",
       "      <td>5042</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12/24/2014</td>\n",
       "      <td>I have been to this place for the third time i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160929</th>\n",
       "      <td>62901</td>\n",
       "      <td>5043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8/4/2011</td>\n",
       "      <td>Horrible service. I saw a customer accidentall...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>25.416667</td>\n",
       "      <td>1.133310</td>\n",
       "      <td>0.197985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160930</th>\n",
       "      <td>201246</td>\n",
       "      <td>5043</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4/14/2013</td>\n",
       "      <td>Its your standard late-night drunk filled coll...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160931</th>\n",
       "      <td>201247</td>\n",
       "      <td>5043</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4/12/2009</td>\n",
       "      <td>If you've ever attended high school in Hamden,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  prod_id  rating  label        date  \\\n",
       "0          5044        0       1      0  11/16/2014   \n",
       "1          5045        0       1      0    9/8/2014   \n",
       "2          5046        0       3      0   10/6/2013   \n",
       "3          5047        0       5      0  11/30/2014   \n",
       "4          5048        0       5      0   8/28/2014   \n",
       "...         ...      ...     ...    ...         ...   \n",
       "160927   265253     5041       5      0  11/15/2011   \n",
       "160928   265316     5042       5      0  12/24/2014   \n",
       "160929    62901     5043       1      0    8/4/2011   \n",
       "160930   201246     5043       2      0   4/14/2013   \n",
       "160931   201247     5043       4      0   4/12/2009   \n",
       "\n",
       "                                                    text_  \\\n",
       "0       Drinks were bad, the hot chocolate was watered...   \n",
       "1       This was the worst experience I've ever had a ...   \n",
       "2       This is located on the site of the old Spruce ...   \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...   \n",
       "4       I love Toast! The food choices are fantastic -...   \n",
       "...                                                   ...   \n",
       "160927  Great local lounge spot! After work and regula...   \n",
       "160928  I have been to this place for the third time i...   \n",
       "160929  Horrible service. I saw a customer accidentall...   \n",
       "160930  Its your standard late-night drunk filled coll...   \n",
       "160931  If you've ever attended high school in Hamden,...   \n",
       "\n",
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "0                                     1                         0.000000   \n",
       "1                                     1                         0.000000   \n",
       "2                                     1                         0.250000   \n",
       "3                                     1                         1.000000   \n",
       "4                                     1                         1.000000   \n",
       "...                                 ...                              ...   \n",
       "160927                                1                         1.000000   \n",
       "160928                                1                         1.000000   \n",
       "160929                               11                         0.916667   \n",
       "160930                                1                         0.000000   \n",
       "160931                                1                         1.000000   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "0                    36.000000                               2.613636   \n",
       "1                   248.000000                               2.613636   \n",
       "2                    45.250000                               0.723817   \n",
       "3                   233.000000                               1.386364   \n",
       "4                   152.000000                               1.386364   \n",
       "...                        ...                                    ...   \n",
       "160927               28.000000                               0.303030   \n",
       "160928              110.000000                               0.000000   \n",
       "160929               25.416667                               1.133310   \n",
       "160930               69.000000                               0.333333   \n",
       "160931              130.000000                               1.666667   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "0                                    0.000000  \n",
       "1                                    0.000000  \n",
       "2                                    0.100917  \n",
       "3                                    0.000000  \n",
       "4                                    0.000000  \n",
       "...                                       ...  \n",
       "160927                               0.000000  \n",
       "160928                               0.000000  \n",
       "160929                               0.197985  \n",
       "160930                               0.000000  \n",
       "160931                               0.000000  \n",
       "\n",
       "[160932 rows x 11 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_meta = df.drop([\"user_id\", \"prod_id\",\"date\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_meta1 =df_no_meta.sample(frac=1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96371</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Best Italian shop in the area. I am a NYC tran...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.540780</td>\n",
       "      <td>0.062032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103402</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Have been going here for years. Food is always...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160285</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I was expecting more from this place. I only e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.863636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99317</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I got take out food here recently and was plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>I've been going here since high school and to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>104.333333</td>\n",
       "      <td>0.962376</td>\n",
       "      <td>0.046731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  label                                              text_  \\\n",
       "96371        5      0  Best Italian shop in the area. I am a NYC tran...   \n",
       "103402       4      0  Have been going here for years. Food is always...   \n",
       "160285       1      0  I was expecting more from this place. I only e...   \n",
       "99317        4      0  I got take out food here recently and was plea...   \n",
       "132540       3      1  I've been going here since high school and to ...   \n",
       "\n",
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "96371                                 2                         0.500000   \n",
       "103402                                1                         1.000000   \n",
       "160285                                1                         0.000000   \n",
       "99317                                 1                         1.000000   \n",
       "132540                                1                         0.333333   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "96371                37.000000                               1.540780   \n",
       "103402               35.000000                               0.138614   \n",
       "160285               66.000000                               1.863636   \n",
       "99317                59.000000                               0.500000   \n",
       "132540              104.333333                               0.962376   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "96371                                0.062032  \n",
       "103402                               0.000000  \n",
       "160285                               0.000000  \n",
       "99317                                0.000000  \n",
       "132540                               0.046731  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_meta1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "df_no_meta1['label']= label_encoder.fit_transform(df_no_meta1['label']) \n",
    "\n",
    "df_no_meta1['label'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96371</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Best Italian shop in the area. I am a NYC tran...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.540780</td>\n",
       "      <td>0.062032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103402</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Have been going here for years. Food is always...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160285</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I was expecting more from this place. I only e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.863636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99317</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I got take out food here recently and was plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>I've been going here since high school and to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>104.333333</td>\n",
       "      <td>0.962376</td>\n",
       "      <td>0.046731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73349</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>The food is so fresh! Love it!</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.924862</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109259</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>More than a sports bar. Good food and service.</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.851449</td>\n",
       "      <td>0.213593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50057</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of those restaurants where you truly feel ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>0.486437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>This place is cute! I went here long time ago....</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.825269</td>\n",
       "      <td>0.038469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>great little place. I used to go there for lun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  label                                              text_  \\\n",
       "96371        5      0  Best Italian shop in the area. I am a NYC tran...   \n",
       "103402       4      0  Have been going here for years. Food is always...   \n",
       "160285       1      0  I was expecting more from this place. I only e...   \n",
       "99317        4      0  I got take out food here recently and was plea...   \n",
       "132540       3      1  I've been going here since high school and to ...   \n",
       "...        ...    ...                                                ...   \n",
       "73349        5      1                     The food is so fresh! Love it!   \n",
       "109259       4      0     More than a sports bar. Good food and service.   \n",
       "50057        4      1  One of those restaurants where you truly feel ...   \n",
       "5192         4      1  This place is cute! I went here long time ago....   \n",
       "128037       5      0  great little place. I used to go there for lun...   \n",
       "\n",
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "96371                                 2                         0.500000   \n",
       "103402                                1                         1.000000   \n",
       "160285                                1                         0.000000   \n",
       "99317                                 1                         1.000000   \n",
       "132540                                1                         0.333333   \n",
       "...                                 ...                              ...   \n",
       "73349                                 1                         1.000000   \n",
       "109259                                3                         0.750000   \n",
       "50057                                 1                         1.000000   \n",
       "5192                                  1                         0.500000   \n",
       "128037                                1                         1.000000   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "96371                37.000000                               1.540780   \n",
       "103402               35.000000                               0.138614   \n",
       "160285               66.000000                               1.863636   \n",
       "99317                59.000000                               0.500000   \n",
       "132540              104.333333                               0.962376   \n",
       "...                        ...                                    ...   \n",
       "73349                 7.000000                               0.924862   \n",
       "109259               15.500000                               0.851449   \n",
       "50057                45.500000                               0.486437   \n",
       "5192                 65.000000                               0.825269   \n",
       "128037               67.000000                               0.000000   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "96371                                0.062032  \n",
       "103402                               0.000000  \n",
       "160285                               0.000000  \n",
       "99317                                0.000000  \n",
       "132540                               0.046731  \n",
       "...                                       ...  \n",
       "73349                                0.000000  \n",
       "109259                               0.213593  \n",
       "50057                                0.000000  \n",
       "5192                                 0.038469  \n",
       "128037                               0.000000  \n",
       "\n",
       "[160932 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_meta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numbers(x):\n",
    "    if bool(re.search(r'\\d', x)):\n",
    "        x = re.sub('[0-9]{5,}', '#####', x)\n",
    "        x = re.sub('[0-9]{4}', '####', x)\n",
    "        x = re.sub('[0-9]{3}', '###', x)\n",
    "        x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prems\\anaconda3\\envs\\swm\\lib\\site-packages\\ipykernel_launcher.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_data(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+\\-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    return text\n",
    "    \n",
    "df_no_meta1['text_'] = df_no_meta1['text_'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96371</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>best italian shop in the area i am a nyc trans...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.540780</td>\n",
       "      <td>0.062032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103402</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>have been going here for years food is always ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160285</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i was expecting more from this place i only ex...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.863636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99317</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i got take out food here recently and was plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>i have been going here since high school and t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>104.333333</td>\n",
       "      <td>0.962376</td>\n",
       "      <td>0.046731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73349</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>the food is so fresh ! love it !</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.924862</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109259</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>more than a sports bar good food and service</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.851449</td>\n",
       "      <td>0.213593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50057</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>one of those restaurants where you truly feel ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>0.486437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>this place is cute ! i went here long time ago...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.825269</td>\n",
       "      <td>0.038469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>great little place i used to go there for lunc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  label                                              text_  \\\n",
       "96371        5      0  best italian shop in the area i am a nyc trans...   \n",
       "103402       4      0  have been going here for years food is always ...   \n",
       "160285       1      0  i was expecting more from this place i only ex...   \n",
       "99317        4      0  i got take out food here recently and was plea...   \n",
       "132540       3      1  i have been going here since high school and t...   \n",
       "...        ...    ...                                                ...   \n",
       "73349        5      1                  the food is so fresh ! love it !    \n",
       "109259       4      0      more than a sports bar good food and service    \n",
       "50057        4      1  one of those restaurants where you truly feel ...   \n",
       "5192         4      1  this place is cute ! i went here long time ago...   \n",
       "128037       5      0  great little place i used to go there for lunc...   \n",
       "\n",
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "96371                                 2                         0.500000   \n",
       "103402                                1                         1.000000   \n",
       "160285                                1                         0.000000   \n",
       "99317                                 1                         1.000000   \n",
       "132540                                1                         0.333333   \n",
       "...                                 ...                              ...   \n",
       "73349                                 1                         1.000000   \n",
       "109259                                3                         0.750000   \n",
       "50057                                 1                         1.000000   \n",
       "5192                                  1                         0.500000   \n",
       "128037                                1                         1.000000   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "96371                37.000000                               1.540780   \n",
       "103402               35.000000                               0.138614   \n",
       "160285               66.000000                               1.863636   \n",
       "99317                59.000000                               0.500000   \n",
       "132540              104.333333                               0.962376   \n",
       "...                        ...                                    ...   \n",
       "73349                 7.000000                               0.924862   \n",
       "109259               15.500000                               0.851449   \n",
       "50057                45.500000                               0.486437   \n",
       "5192                 65.000000                               0.825269   \n",
       "128037               67.000000                               0.000000   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "96371                                0.062032  \n",
       "103402                               0.000000  \n",
       "160285                               0.000000  \n",
       "99317                                0.000000  \n",
       "132540                               0.046731  \n",
       "...                                       ...  \n",
       "73349                                0.000000  \n",
       "109259                               0.213593  \n",
       "50057                                0.000000  \n",
       "5192                                 0.038469  \n",
       "128037                               0.000000  \n",
       "\n",
       "[160932 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_meta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.map(lambda a: clean_data(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = df_no_meta1.text_\n",
    "X_numeric = df_no_meta1[['maximum_review_per_day_for_user','percent_postive_reviews_by_user','max_user_review_length','avg_user_rating_deviation_per_product','max_cosine_similarity_to_user_reviews']]\n",
    "y = df_no_meta1.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text, x_test_text, x_train_numeric, x_test_numeric, y_train, y_test = train_test_split(\n",
    "    X_text, X_numeric, y, stratify=y, test_size=0.2, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None,lower=True,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',split=' ',char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text = tokenizer.texts_to_sequences(x_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_text = tokenizer.texts_to_sequences(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = tokenizer.texts_to_sequences(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 87775\n",
      "Longest comment size: 995\n",
      "Average comment size: 105.61196033107151\n",
      "Stdev of comment size: 102.15050913314423\n",
      "Max comment size: 412\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_index)\n",
    "print('Vocab size: {}'.format(vocab_size))\n",
    "longest = max(len(seq) for seq in X_text)\n",
    "print(\"Longest comment size: {}\".format(longest))\n",
    "average = np.mean([len(seq) for seq in X_text])\n",
    "print(\"Average comment size: {}\".format(average))\n",
    "stdev = np.std([len(seq) for seq in X_text])\n",
    "print(\"Stdev of comment size: {}\".format(stdev))\n",
    "max_len = int(average + stdev * 3)\n",
    "print('Max comment size: {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_post_x_train = pad_sequences(x_train_text, maxlen=max_len, padding='post', truncating='post')\n",
    "processed_post_x_test = pad_sequences(x_test_text, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_x_train = pad_sequences(x_train_text, maxlen=max_len)\n",
    "processed_x_test = pad_sequences(x_test_text, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pre_x_train = pad_sequences(x_train_text, maxlen=max_len)\n",
    "processed_pre_x_test = pad_sequences(x_test_text, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (120699, 412)\n",
      "x_test shape: (40233, 412)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', processed_x_train.shape)\n",
    "print('x_test shape:', processed_x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "k = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        k += 1\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        #self.init = initializations.get('glorot_uniform')\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
    "\n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "    #print weigthted_input.shape\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    review_input = Input(shape=(max_len,), dtype='int32')\n",
    "    review_input_post = Input(shape=(max_len,), dtype='int32')\n",
    "    mnr_input = Input(shape=(1,), dtype='float32')  # Add MNR as a numeric input\n",
    "    pr_input = Input(shape=(1,), dtype='float32')   # Add PR as a numeric input\n",
    "    rl_input = Input(shape=(1,), dtype='float32')   # Add RL as a numeric input\n",
    "    rd_input = Input(shape=(1,), dtype='float32')   # Add RD as a numeric input\n",
    "    mcs_input = Input(shape=(1,), dtype='float32')  # Add MCS as a numeric input\n",
    "\n",
    "    x1 = Embedding(vocab_size + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(review_input)\n",
    "    x1 = Bidirectional(LSTM(60, return_sequences=True))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Attention(max_len)(x1)\n",
    "\n",
    "    x2 = Embedding(vocab_size + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(review_input_post)\n",
    "    x2 = Bidirectional(LSTM(60, return_sequences=True))(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    x2 = Attention(max_len)(x2)\n",
    "\n",
    "    x = concatenate([x1, x2, mnr_input, pr_input, rl_input, rd_input, mcs_input])\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x= Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[review_input, review_input_post, mnr_input, pr_input, rl_input, rd_input, mcs_input], outputs=preds)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 412)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 412)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 412, 100)     8777600     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 412, 100)     8777600     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 412, 120)     77280       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 412, 120)     77280       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 412, 120)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 412, 120)     0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 120)          532         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 120)          532         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 245)          0           attention_2[0][0]                \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           12300       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 50)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50)           200         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            51          batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 17,723,375\n",
      "Trainable params: 17,723,275\n",
      "Non-trainable params: 100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.505807</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7516</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.687131</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148778</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88431</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65035</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.363070</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123085</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12978</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.112426</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111290</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.208904</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151097</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97457</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.199515</td>\n",
       "      <td>0.336097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120699 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "1889                                  1                              0.0   \n",
       "7516                                  1                              1.0   \n",
       "148778                                1                              1.0   \n",
       "88431                                 1                              1.0   \n",
       "65035                                 2                              0.5   \n",
       "...                                 ...                              ...   \n",
       "123085                                1                              1.0   \n",
       "12978                                 1                              1.0   \n",
       "111290                                1                              1.0   \n",
       "151097                                1                              0.0   \n",
       "97457                                 1                              1.0   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "1889                      14.0                               0.505807   \n",
       "7516                      38.0                               0.687131   \n",
       "148778                    65.0                               0.769231   \n",
       "88431                    154.0                               1.000000   \n",
       "65035                     31.0                               0.363070   \n",
       "...                        ...                                    ...   \n",
       "123085                    58.0                               0.842105   \n",
       "12978                     93.0                               1.112426   \n",
       "111290                    21.0                               1.208904   \n",
       "151097                    34.0                               1.714286   \n",
       "97457                     10.0                               0.199515   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "1889                                 0.000000  \n",
       "7516                                 0.000000  \n",
       "148778                               0.000000  \n",
       "88431                                0.000000  \n",
       "65035                                0.000000  \n",
       "...                                       ...  \n",
       "123085                               0.000000  \n",
       "12978                                0.000000  \n",
       "111290                               0.000000  \n",
       "151097                               0.000000  \n",
       "97457                                0.336097  \n",
       "\n",
       "[120699 rows x 5 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3772/3772 [==============================] - 450s 117ms/step - loss: 0.5640 - accuracy: 0.7081 - val_loss: 0.5187 - val_accuracy: 0.7373\n",
      "Epoch 2/10\n",
      "3772/3772 [==============================] - 446s 118ms/step - loss: 0.4592 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7440\n",
      "Epoch 3/10\n",
      "3772/3772 [==============================] - 457s 121ms/step - loss: 0.3916 - accuracy: 0.8236 - val_loss: 0.5506 - val_accuracy: 0.7450\n",
      "Epoch 4/10\n",
      "3772/3772 [==============================] - 454s 120ms/step - loss: 0.3364 - accuracy: 0.8538 - val_loss: 0.5773 - val_accuracy: 0.7377\n",
      "Epoch 5/10\n",
      "3772/3772 [==============================] - 453s 120ms/step - loss: 0.2872 - accuracy: 0.8768 - val_loss: 0.6455 - val_accuracy: 0.7330\n",
      "Epoch 6/10\n",
      "3772/3772 [==============================] - 446s 118ms/step - loss: 0.2419 - accuracy: 0.8978 - val_loss: 0.7258 - val_accuracy: 0.7262\n",
      "Epoch 7/10\n",
      "3772/3772 [==============================] - 444s 118ms/step - loss: 0.2013 - accuracy: 0.9160 - val_loss: 0.8634 - val_accuracy: 0.7174\n",
      "Epoch 8/10\n",
      "3772/3772 [==============================] - 442s 117ms/step - loss: 0.1684 - accuracy: 0.9307 - val_loss: 1.0090 - val_accuracy: 0.7135\n",
      "Epoch 9/10\n",
      "3772/3772 [==============================] - 438s 116ms/step - loss: 0.1415 - accuracy: 0.9426 - val_loss: 1.0712 - val_accuracy: 0.7123\n",
      "Epoch 10/10\n",
      "3772/3772 [==============================] - 416s 110ms/step - loss: 0.1209 - accuracy: 0.9520 - val_loss: 1.1988 - val_accuracy: 0.7115\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([processed_x_train,processed_pre_x_train,x_train_numeric['maximum_review_per_day_for_user'],x_train_numeric['percent_postive_reviews_by_user'],x_train_numeric['max_user_review_length'],x_train_numeric['avg_user_rating_deviation_per_product'],x_train_numeric['max_cosine_similarity_to_user_reviews']],y_train, validation_data=([processed_x_test,processed_pre_x_test,x_test_numeric['maximum_review_per_day_for_user'],x_test_numeric['percent_postive_reviews_by_user'],x_test_numeric['max_user_review_length'],x_test_numeric['avg_user_rating_deviation_per_product'],x_test_numeric['max_cosine_similarity_to_user_reviews']],y_test), epochs=10,batch_size=32,callbacks=[early_stopping_monitor],verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
