{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Activation,\n",
    "    MaxPooling1D,\n",
    "    Flatten,\n",
    "    Embedding,\n",
    "    Conv1D,\n",
    "    GlobalMaxPooling1D,\n",
    "    BatchNormalization,\n",
    "    CuDNNGRU,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Input,\n",
    "    concatenate,\n",
    ")\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "from numpy import random\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prems\\anaconda3\\envs\\swm\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('olddata/reviewContent+metadata.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9/8/2014</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11/30/2014</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608593</th>\n",
       "      <td>119664.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1/20/2013</td>\n",
       "      <td>When I first moved to the area I must say I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608594</th>\n",
       "      <td>56277.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/12/2012</td>\n",
       "      <td>Kind of pricey. I guess I expected a ridiculou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>265320.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8/22/2012</td>\n",
       "      <td>Stopped by this restaurant yesterday, we just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>161722.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5/11/2011</td>\n",
       "      <td>Finally checked out The Best Subs in Claremont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>78454.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7/17/2010</td>\n",
       "      <td>Just got me some \"Best Subs\" and I gotta say, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608598 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  prod_id  rating  label        date  \\\n",
       "0         5044.0      0.0     1.0   -1.0  11/16/2014   \n",
       "1         5045.0      0.0     1.0   -1.0    9/8/2014   \n",
       "2         5046.0      0.0     3.0   -1.0   10/6/2013   \n",
       "3         5047.0      0.0     5.0   -1.0  11/30/2014   \n",
       "4         5048.0      0.0     5.0   -1.0   8/28/2014   \n",
       "...          ...      ...     ...    ...         ...   \n",
       "608593  119664.0   5039.0     4.0    1.0   1/20/2013   \n",
       "608594   56277.0   5039.0     2.0    1.0  11/12/2012   \n",
       "608595  265320.0   5039.0     1.0    1.0   8/22/2012   \n",
       "608596  161722.0   5039.0     4.0    1.0   5/11/2011   \n",
       "608597   78454.0   5039.0     4.0    1.0   7/17/2010   \n",
       "\n",
       "                                                    text_  \n",
       "0       Drinks were bad, the hot chocolate was watered...  \n",
       "1       This was the worst experience I've ever had a ...  \n",
       "2       This is located on the site of the old Spruce ...  \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...  \n",
       "4       I love Toast! The food choices are fantastic -...  \n",
       "...                                                   ...  \n",
       "608593  When I first moved to the area I must say I wa...  \n",
       "608594  Kind of pricey. I guess I expected a ridiculou...  \n",
       "608595  Stopped by this restaurant yesterday, we just ...  \n",
       "608596  Finally checked out The Best Subs in Claremont...  \n",
       "608597  Just got me some \"Best Subs\" and I gotta say, ...  \n",
       "\n",
       "[608598 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>608598.000000</td>\n",
       "      <td>608598.000000</td>\n",
       "      <td>608598.000000</td>\n",
       "      <td>608598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89642.634603</td>\n",
       "      <td>2564.991760</td>\n",
       "      <td>3.923595</td>\n",
       "      <td>0.735569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>73873.157594</td>\n",
       "      <td>1447.929346</td>\n",
       "      <td>1.147472</td>\n",
       "      <td>0.677450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5044.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25495.250000</td>\n",
       "      <td>1345.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66770.000000</td>\n",
       "      <td>2616.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>142269.000000</td>\n",
       "      <td>3768.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>265320.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        prod_id         rating          label\n",
       "count  608598.000000  608598.000000  608598.000000  608598.000000\n",
       "mean    89642.634603    2564.991760       3.923595       0.735569\n",
       "std     73873.157594    1447.929346       1.147472       0.677450\n",
       "min      5044.000000       0.000000       1.000000      -1.000000\n",
       "25%     25495.250000    1345.000000       3.000000       1.000000\n",
       "50%     66770.000000    2616.000000       4.000000       1.000000\n",
       "75%    142269.000000    3768.000000       5.000000       1.000000\n",
       "max    265320.000000    5043.000000       5.000000       1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Review Length: 5000\n",
      "Minimum Review Length: 1\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'text_' column contains the reviews\n",
    "max_review_length = df['text_'].apply(len).max()\n",
    "min_review_length = df['text_'].apply(len).min()\n",
    "\n",
    "print(f\"Maximum Review Length: {max_review_length}\")\n",
    "print(f\"Minimum Review Length: {min_review_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews with Length 1:\n",
      "526       -\n",
      "22764     a\n",
      "25053     I\n",
      "27779     .\n",
      "29073     !\n",
      "50634     .\n",
      "52283     X\n",
      "95367     .\n",
      "107159    .\n",
      "121220    J\n",
      "123032    .\n",
      "127073    -\n",
      "147737    h\n",
      "151219    .\n",
      "155171    A\n",
      "159153    .\n",
      "163349    .\n",
      "164741    .\n",
      "185989    .\n",
      "191799    N\n",
      "194878    !\n",
      "203617    f\n",
      "215340    h\n",
      "240496    a\n",
      "241129    N\n",
      "243414    .\n",
      "269098    .\n",
      "284220    .\n",
      "295912    .\n",
      "310130    .\n",
      "318126    .\n",
      "331864    b\n",
      "374621    5\n",
      "388302    .\n",
      "394531    -\n",
      "410264    .\n",
      "411009    .\n",
      "432470    .\n",
      "436863    .\n",
      "450002    .\n",
      "473665    .\n",
      "496995    A\n",
      "498465    .\n",
      "500825    .\n",
      "506167    .\n",
      "519394    .\n",
      "522682    I\n",
      "543742    .\n",
      "552760    a\n",
      "559335    ?\n",
      "578877    .\n",
      "579763    .\n",
      "591571    .\n",
      "593161    .\n",
      "Name: text_, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'text_' column contains the reviews\n",
    "reviews_length_one = df[df['text_'].apply(len) == 1]['text_']\n",
    "\n",
    "print(\"Reviews with Length 1:\")\n",
    "print(reviews_length_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5044"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['prod_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate Maximum Number of Reviews (MNR)\n",
    "def calculate_mnr(df1):\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df1['reviews_per_day'] = df1.groupby(['user_id', df1['date'].dt.date])['user_id'].transform('count')\n",
    "    max_reviews_per_day = df1.groupby('user_id')['reviews_per_day'].max()\n",
    "    return max_reviews_per_day\n",
    "\n",
    "# Function to calculate Percentage of Positive Reviews (PR)\n",
    "def calculate_pr(df1):\n",
    "    # Group reviews by user_id and create a list of reviews for each user\n",
    "    user_reviews = df1.groupby('user_id')['rating'].apply(list).reset_index(name='reviews')\n",
    "\n",
    "    # Calculate the percentage of positive reviews for each user\n",
    "    user_reviews['pr'] = user_reviews['reviews'].apply(\n",
    "        lambda reviews: (\n",
    "            sum(rating in [4, 5] for rating in reviews) / len(reviews)\n",
    "        ) if len(reviews) > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Merge the result back to the original dataframe\n",
    "    pr_df = user_reviews[['user_id', 'pr']]\n",
    "    return pr_df\n",
    "\n",
    "# Function to calculate Review Length (RL)\n",
    "def calculate_rl(df1):\n",
    "    df1['review_length'] = df1['text_'].apply(lambda x: len(x.split()))\n",
    "    avg_review_length = df1.groupby('user_id')['review_length'].mean()\n",
    "    return avg_review_length\n",
    "\n",
    "# Function to calculate Reviewer Deviation (RD)\n",
    "def calculate_rd(df1):\n",
    "    average_ratings_per_product = df1.groupby('prod_id')['rating'].mean()\n",
    "    tempdf = pd.merge(df1, average_ratings_per_product, on='prod_id', how='left')\n",
    "    tempdf['rating_deviation'] = np.abs(tempdf['rating_x'] - tempdf['rating_y'])\n",
    "    average_deviation_per_user = tempdf.groupby('user_id')['rating_deviation'].mean()\n",
    "    return average_deviation_per_user\n",
    "\n",
    "# Function to calculate Maximum Content Similarity (MCS)\n",
    "def calculate_mcs(df1):\n",
    "    # Group by user_id and collect all reviews\n",
    "    user_reviews = df1.groupby('user_id')['text_'].agg(lambda x: list(map(str, x))).reset_index()\n",
    "\n",
    "    # Initialize lists to store user_ids and max similarities\n",
    "    user_ids = []\n",
    "    max_similarities = []\n",
    "    user_reviews_dict = dict(zip(user_reviews['user_id'], user_reviews['text_']))\n",
    "\n",
    "\n",
    "\n",
    "    # Create a TF-IDF vectorizer outside the loop\n",
    "    vectorizer = TfidfVectorizer(stop_words=None)\n",
    "\n",
    "    for user_id, reviews in user_reviews_dict.items():\n",
    "        # If there is only one review, similarity is 0\n",
    "        if len(reviews) <= 1:\n",
    "            user_ids.append(user_id)\n",
    "            max_similarities.append(0)\n",
    "        else:\n",
    "            reviews = list(map(str, reviews))\n",
    "            try:\n",
    "                # Calculate TF-IDF vectors and cosine similarity between all pairs of reviews\n",
    "                tfidf_matrix = vectorizer.fit_transform(reviews)\n",
    "                similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "                # Set the diagonal elements to 0 to avoid self-comparison\n",
    "                np.fill_diagonal(similarity_matrix, 0)\n",
    "\n",
    "                # Find the maximum similarity value\n",
    "                max_similarity = np.max(similarity_matrix)\n",
    "                \n",
    "                # Append user_id and corresponding maximum similarity\n",
    "                user_ids.append(user_id)\n",
    "                max_similarities.append(max_similarity)\n",
    "            except Exception as e:\n",
    "                print(\"these reviews failed : \", user_id, reviews)\n",
    "                user_ids.append(user_id)\n",
    "                max_similarities.append(0)\n",
    "    return pd.DataFrame({'user_id': user_ids, 'mcs': max_similarities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9/8/2014</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11/30/2014</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608593</th>\n",
       "      <td>119664.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1/20/2013</td>\n",
       "      <td>When I first moved to the area I must say I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608594</th>\n",
       "      <td>56277.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/12/2012</td>\n",
       "      <td>Kind of pricey. I guess I expected a ridiculou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>265320.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8/22/2012</td>\n",
       "      <td>Stopped by this restaurant yesterday, we just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>161722.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5/11/2011</td>\n",
       "      <td>Finally checked out The Best Subs in Claremont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>78454.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7/17/2010</td>\n",
       "      <td>Just got me some \"Best Subs\" and I gotta say, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608598 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  prod_id  rating  label        date  \\\n",
       "0         5044.0      0.0     1.0   -1.0  11/16/2014   \n",
       "1         5045.0      0.0     1.0   -1.0    9/8/2014   \n",
       "2         5046.0      0.0     3.0   -1.0   10/6/2013   \n",
       "3         5047.0      0.0     5.0   -1.0  11/30/2014   \n",
       "4         5048.0      0.0     5.0   -1.0   8/28/2014   \n",
       "...          ...      ...     ...    ...         ...   \n",
       "608593  119664.0   5039.0     4.0    1.0   1/20/2013   \n",
       "608594   56277.0   5039.0     2.0    1.0  11/12/2012   \n",
       "608595  265320.0   5039.0     1.0    1.0   8/22/2012   \n",
       "608596  161722.0   5039.0     4.0    1.0   5/11/2011   \n",
       "608597   78454.0   5039.0     4.0    1.0   7/17/2010   \n",
       "\n",
       "                                                    text_  \n",
       "0       Drinks were bad, the hot chocolate was watered...  \n",
       "1       This was the worst experience I've ever had a ...  \n",
       "2       This is located on the site of the old Spruce ...  \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...  \n",
       "4       I love Toast! The food choices are fantastic -...  \n",
       "...                                                   ...  \n",
       "608593  When I first moved to the area I must say I wa...  \n",
       "608594  Kind of pricey. I guess I expected a ridiculou...  \n",
       "608595  Stopped by this restaurant yesterday, we just ...  \n",
       "608596  Finally checked out The Best Subs in Claremont...  \n",
       "608597  Just got me some \"Best Subs\" and I gotta say, ...  \n",
       "\n",
       "[608598 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MNR...\n",
      "MNR calculation completed.\n",
      "Calculating PR...\n",
      "PR calculation completed.\n",
      "Calculating RL...\n",
      "RL calculation completed.\n",
      "Calculating RD...\n",
      "RD calculation completed.\n",
      "Calculating MCS...\n",
      "these reviews failed :  86744.0 ['.', '.', '.']\n",
      "these reviews failed :  88926.0 ['-', '-']\n",
      "MCS calculation completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Calculating MNR...\")\n",
    "mnr_df = calculate_mnr(copy_df)\n",
    "print(\"MNR calculation completed.\")\n",
    "\n",
    "print(\"Calculating PR...\")\n",
    "pr_df = calculate_pr(copy_df)\n",
    "print(\"PR calculation completed.\")\n",
    "\n",
    "print(\"Calculating RL...\")\n",
    "rl_df = calculate_rl(copy_df)\n",
    "print(\"RL calculation completed.\")\n",
    "\n",
    "print(\"Calculating RD...\")\n",
    "rd_df = calculate_rd(copy_df)\n",
    "print(\"RD calculation completed.\")\n",
    "\n",
    "print(\"Calculating MCS...\")\n",
    "mcs_df = calculate_mcs(copy_df)\n",
    "print(\"MCS calculation completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9/8/2014</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11/30/2014</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608593</th>\n",
       "      <td>119664.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1/20/2013</td>\n",
       "      <td>When I first moved to the area I must say I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608594</th>\n",
       "      <td>56277.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/12/2012</td>\n",
       "      <td>Kind of pricey. I guess I expected a ridiculou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>265320.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8/22/2012</td>\n",
       "      <td>Stopped by this restaurant yesterday, we just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>161722.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5/11/2011</td>\n",
       "      <td>Finally checked out The Best Subs in Claremont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>78454.0</td>\n",
       "      <td>5039.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7/17/2010</td>\n",
       "      <td>Just got me some \"Best Subs\" and I gotta say, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608598 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  prod_id  rating  label        date  \\\n",
       "0         5044.0      0.0     1.0   -1.0  11/16/2014   \n",
       "1         5045.0      0.0     1.0   -1.0    9/8/2014   \n",
       "2         5046.0      0.0     3.0   -1.0   10/6/2013   \n",
       "3         5047.0      0.0     5.0   -1.0  11/30/2014   \n",
       "4         5048.0      0.0     5.0   -1.0   8/28/2014   \n",
       "...          ...      ...     ...    ...         ...   \n",
       "608593  119664.0   5039.0     4.0    1.0   1/20/2013   \n",
       "608594   56277.0   5039.0     2.0    1.0  11/12/2012   \n",
       "608595  265320.0   5039.0     1.0    1.0   8/22/2012   \n",
       "608596  161722.0   5039.0     4.0    1.0   5/11/2011   \n",
       "608597   78454.0   5039.0     4.0    1.0   7/17/2010   \n",
       "\n",
       "                                                    text_  \n",
       "0       Drinks were bad, the hot chocolate was watered...  \n",
       "1       This was the worst experience I've ever had a ...  \n",
       "2       This is located on the site of the old Spruce ...  \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...  \n",
       "4       I love Toast! The food choices are fantastic -...  \n",
       "...                                                   ...  \n",
       "608593  When I first moved to the area I must say I wa...  \n",
       "608594  Kind of pricey. I guess I expected a ridiculou...  \n",
       "608595  Stopped by this restaurant yesterday, we just ...  \n",
       "608596  Finally checked out The Best Subs in Claremont...  \n",
       "608597  Just got me some \"Best Subs\" and I gotta say, ...  \n",
       "\n",
       "[608598 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv('reviewContent+metadataBalanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge the calculated features with the original dataset on 'user_id'\n",
    "balanced_df = balanced_df.merge(mnr_df, on='user_id', how='left')\n",
    "balanced_df = balanced_df.merge(pr_df, on='user_id', how='left')\n",
    "balanced_df = balanced_df.merge(rl_df, on='user_id', how='left')\n",
    "balanced_df = balanced_df.merge(rd_df, on='user_id', how='left')\n",
    "balanced_df = balanced_df.merge(mcs_df, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = balanced_df.rename(columns={'reviews_per_day': 'maximum_review_per_day_for_user', 'pr': 'percent_postive_reviews_by_user','review_length': 'max_user_review_length','rating_deviation': 'avg_user_rating_deviation_per_product','mcs': 'max_cosine_similarity_to_user_reviews'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>text_</th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.613636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9/8/2014</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>2.613636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10/6/2013</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>0.588522</td>\n",
       "      <td>0.322332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/30/2014</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>1.386364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>1.386364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160927</th>\n",
       "      <td>265253</td>\n",
       "      <td>5041</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11/15/2011</td>\n",
       "      <td>Great local lounge spot! After work and regula...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160928</th>\n",
       "      <td>265316</td>\n",
       "      <td>5042</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12/24/2014</td>\n",
       "      <td>I have been to this place for the third time i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160929</th>\n",
       "      <td>62901</td>\n",
       "      <td>5043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8/4/2011</td>\n",
       "      <td>Horrible service. I saw a customer accidentall...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>25.416667</td>\n",
       "      <td>0.822530</td>\n",
       "      <td>0.204057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160930</th>\n",
       "      <td>201246</td>\n",
       "      <td>5043</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4/14/2013</td>\n",
       "      <td>Its your standard late-night drunk filled coll...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160931</th>\n",
       "      <td>201247</td>\n",
       "      <td>5043</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4/12/2009</td>\n",
       "      <td>If you've ever attended high school in Hamden,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  prod_id  rating  label        date  \\\n",
       "0          5044        0       1      0  11/16/2014   \n",
       "1          5045        0       1      0    9/8/2014   \n",
       "2          5046        0       3      0   10/6/2013   \n",
       "3          5047        0       5      0  11/30/2014   \n",
       "4          5048        0       5      0   8/28/2014   \n",
       "...         ...      ...     ...    ...         ...   \n",
       "160927   265253     5041       5      0  11/15/2011   \n",
       "160928   265316     5042       5      0  12/24/2014   \n",
       "160929    62901     5043       1      0    8/4/2011   \n",
       "160930   201246     5043       2      0   4/14/2013   \n",
       "160931   201247     5043       4      0   4/12/2009   \n",
       "\n",
       "                                                    text_  \\\n",
       "0       Drinks were bad, the hot chocolate was watered...   \n",
       "1       This was the worst experience I've ever had a ...   \n",
       "2       This is located on the site of the old Spruce ...   \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...   \n",
       "4       I love Toast! The food choices are fantastic -...   \n",
       "...                                                   ...   \n",
       "160927  Great local lounge spot! After work and regula...   \n",
       "160928  I have been to this place for the third time i...   \n",
       "160929  Horrible service. I saw a customer accidentall...   \n",
       "160930  Its your standard late-night drunk filled coll...   \n",
       "160931  If you've ever attended high school in Hamden,...   \n",
       "\n",
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "0                                     1                         0.000000   \n",
       "1                                     1                         0.000000   \n",
       "2                                     1                         0.250000   \n",
       "3                                     1                         1.000000   \n",
       "4                                     1                         1.000000   \n",
       "...                                 ...                              ...   \n",
       "160927                                1                         1.000000   \n",
       "160928                                1                         1.000000   \n",
       "160929                               11                         0.916667   \n",
       "160930                                1                         0.000000   \n",
       "160931                                1                         1.000000   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "0                    36.000000                               2.613636   \n",
       "1                   248.000000                               2.613636   \n",
       "2                    45.250000                               0.588522   \n",
       "3                   233.000000                               1.386364   \n",
       "4                   152.000000                               1.386364   \n",
       "...                        ...                                    ...   \n",
       "160927               28.000000                               0.828125   \n",
       "160928              110.000000                               0.000000   \n",
       "160929               25.416667                               0.822530   \n",
       "160930               69.000000                               0.675000   \n",
       "160931              130.000000                               1.325000   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "0                                    0.000000  \n",
       "1                                    0.000000  \n",
       "2                                    0.322332  \n",
       "3                                    0.000000  \n",
       "4                                    0.000000  \n",
       "...                                       ...  \n",
       "160927                               0.000000  \n",
       "160928                               0.000000  \n",
       "160929                               0.204057  \n",
       "160930                               0.000000  \n",
       "160931                               0.000000  \n",
       "\n",
       "[160932 rows x 11 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_meta = balanced_df.drop([\"user_id\", \"prod_id\",\"date\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_meta1 =df_no_meta.sample(frac=1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96371</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Best Italian shop in the area. I am a NYC tran...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.636018</td>\n",
       "      <td>0.156496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103402</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Have been going here for years. Food is always...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.188327</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160285</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I was expecting more from this place. I only e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.355705</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99317</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I got take out food here recently and was plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>I've been going here since high school and to ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>134.380952</td>\n",
       "      <td>0.832195</td>\n",
       "      <td>0.396967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  label                                              text_  \\\n",
       "96371        5      0  Best Italian shop in the area. I am a NYC tran...   \n",
       "103402       4      0  Have been going here for years. Food is always...   \n",
       "160285       1      0  I was expecting more from this place. I only e...   \n",
       "99317        4      0  I got take out food here recently and was plea...   \n",
       "132540       3      1  I've been going here since high school and to ...   \n",
       "\n",
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "96371                                 2                         0.500000   \n",
       "103402                                1                         1.000000   \n",
       "160285                                1                         0.000000   \n",
       "99317                                 1                         1.000000   \n",
       "132540                                5                         0.619048   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "96371                37.000000                               1.636018   \n",
       "103402               35.000000                               0.188327   \n",
       "160285               66.000000                               2.355705   \n",
       "99317                59.000000                               0.153061   \n",
       "132540              134.380952                               0.832195   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "96371                                0.156496  \n",
       "103402                               0.000000  \n",
       "160285                               0.000000  \n",
       "99317                                0.000000  \n",
       "132540                               0.396967  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_meta1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "df_no_meta1['label']= label_encoder.fit_transform(df_no_meta1['label']) \n",
    "\n",
    "df_no_meta1['label'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96371</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Best Italian shop in the area. I am a NYC tran...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.636018</td>\n",
       "      <td>0.156496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103402</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Have been going here for years. Food is always...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.188327</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160285</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I was expecting more from this place. I only e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.355705</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99317</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I got take out food here recently and was plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>I've been going here since high school and to ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>134.380952</td>\n",
       "      <td>0.832195</td>\n",
       "      <td>0.396967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73349</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>The food is so fresh! Love it!</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.924862</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109259</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>More than a sports bar. Good food and service.</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.547648</td>\n",
       "      <td>0.178596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50057</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of those restaurants where you truly feel ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>68.090909</td>\n",
       "      <td>0.729668</td>\n",
       "      <td>0.241765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>This place is cute! I went here long time ago....</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>0.828831</td>\n",
       "      <td>0.383445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>great little place. I used to go there for lun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  label                                              text_  \\\n",
       "96371        5      0  Best Italian shop in the area. I am a NYC tran...   \n",
       "103402       4      0  Have been going here for years. Food is always...   \n",
       "160285       1      0  I was expecting more from this place. I only e...   \n",
       "99317        4      0  I got take out food here recently and was plea...   \n",
       "132540       3      1  I've been going here since high school and to ...   \n",
       "...        ...    ...                                                ...   \n",
       "73349        5      1                     The food is so fresh! Love it!   \n",
       "109259       4      0     More than a sports bar. Good food and service.   \n",
       "50057        4      1  One of those restaurants where you truly feel ...   \n",
       "5192         4      1  This place is cute! I went here long time ago....   \n",
       "128037       5      0  great little place. I used to go there for lun...   \n",
       "\n",
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "96371                                 2                         0.500000   \n",
       "103402                                1                         1.000000   \n",
       "160285                                1                         0.000000   \n",
       "99317                                 1                         1.000000   \n",
       "132540                                5                         0.619048   \n",
       "...                                 ...                              ...   \n",
       "73349                                 1                         1.000000   \n",
       "109259                                3                         0.750000   \n",
       "50057                                 3                         0.636364   \n",
       "5192                                  2                         0.666667   \n",
       "128037                                1                         1.000000   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "96371                37.000000                               1.636018   \n",
       "103402               35.000000                               0.188327   \n",
       "160285               66.000000                               2.355705   \n",
       "99317                59.000000                               0.153061   \n",
       "132540              134.380952                               0.832195   \n",
       "...                        ...                                    ...   \n",
       "73349                 7.000000                               0.924862   \n",
       "109259               15.500000                               0.547648   \n",
       "50057                68.090909                               0.729668   \n",
       "5192                 75.333333                               0.828831   \n",
       "128037               67.000000                               0.571429   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "96371                                0.156496  \n",
       "103402                               0.000000  \n",
       "160285                               0.000000  \n",
       "99317                                0.000000  \n",
       "132540                               0.396967  \n",
       "...                                       ...  \n",
       "73349                                0.000000  \n",
       "109259                               0.178596  \n",
       "50057                                0.241765  \n",
       "5192                                 0.383445  \n",
       "128037                               0.000000  \n",
       "\n",
       "[160932 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_meta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numbers(x):\n",
    "    if bool(re.search(r'\\d', x)):\n",
    "        x = re.sub('[0-9]{5,}', '#####', x)\n",
    "        x = re.sub('[0-9]{4}', '####', x)\n",
    "        x = re.sub('[0-9]{3}', '###', x)\n",
    "        x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prems\\anaconda3\\envs\\swm\\lib\\site-packages\\ipykernel_launcher.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_data(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+\\-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    return text\n",
    "    \n",
    "df_no_meta1['text_'] = df_no_meta1['text_'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96371</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>best italian shop in the area i am a nyc trans...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.636018</td>\n",
       "      <td>0.156496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103402</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>have been going here for years food is always ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.188327</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160285</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i was expecting more from this place i only ex...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.355705</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99317</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i got take out food here recently and was plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>i have been going here since high school and t...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>134.380952</td>\n",
       "      <td>0.832195</td>\n",
       "      <td>0.396967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73349</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>the food is so fresh ! love it !</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.924862</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109259</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>more than a sports bar good food and service</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.547648</td>\n",
       "      <td>0.178596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50057</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>one of those restaurants where you truly feel ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>68.090909</td>\n",
       "      <td>0.729668</td>\n",
       "      <td>0.241765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>this place is cute ! i went here long time ago...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>0.828831</td>\n",
       "      <td>0.383445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>great little place i used to go there for lunc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160932 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  label                                              text_  \\\n",
       "96371        5      0  best italian shop in the area i am a nyc trans...   \n",
       "103402       4      0  have been going here for years food is always ...   \n",
       "160285       1      0  i was expecting more from this place i only ex...   \n",
       "99317        4      0  i got take out food here recently and was plea...   \n",
       "132540       3      1  i have been going here since high school and t...   \n",
       "...        ...    ...                                                ...   \n",
       "73349        5      1                  the food is so fresh ! love it !    \n",
       "109259       4      0      more than a sports bar good food and service    \n",
       "50057        4      1  one of those restaurants where you truly feel ...   \n",
       "5192         4      1  this place is cute ! i went here long time ago...   \n",
       "128037       5      0  great little place i used to go there for lunc...   \n",
       "\n",
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "96371                                 2                         0.500000   \n",
       "103402                                1                         1.000000   \n",
       "160285                                1                         0.000000   \n",
       "99317                                 1                         1.000000   \n",
       "132540                                5                         0.619048   \n",
       "...                                 ...                              ...   \n",
       "73349                                 1                         1.000000   \n",
       "109259                                3                         0.750000   \n",
       "50057                                 3                         0.636364   \n",
       "5192                                  2                         0.666667   \n",
       "128037                                1                         1.000000   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "96371                37.000000                               1.636018   \n",
       "103402               35.000000                               0.188327   \n",
       "160285               66.000000                               2.355705   \n",
       "99317                59.000000                               0.153061   \n",
       "132540              134.380952                               0.832195   \n",
       "...                        ...                                    ...   \n",
       "73349                 7.000000                               0.924862   \n",
       "109259               15.500000                               0.547648   \n",
       "50057                68.090909                               0.729668   \n",
       "5192                 75.333333                               0.828831   \n",
       "128037               67.000000                               0.571429   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  \n",
       "96371                                0.156496  \n",
       "103402                               0.000000  \n",
       "160285                               0.000000  \n",
       "99317                                0.000000  \n",
       "132540                               0.396967  \n",
       "...                                       ...  \n",
       "73349                                0.000000  \n",
       "109259                               0.178596  \n",
       "50057                                0.241765  \n",
       "5192                                 0.383445  \n",
       "128037                               0.000000  \n",
       "\n",
       "[160932 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_meta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.map(lambda a: clean_data(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = df_no_meta1.text_\n",
    "X_numeric = df_no_meta1[['maximum_review_per_day_for_user','percent_postive_reviews_by_user','max_user_review_length','avg_user_rating_deviation_per_product','max_cosine_similarity_to_user_reviews','rating']]\n",
    "y = df_no_meta1.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text, x_test_text, x_train_numeric, x_test_numeric, y_train, y_test = train_test_split(\n",
    "    X_text, X_numeric, y, stratify=y, test_size=0.2, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None,lower=True,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',split=' ',char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text = tokenizer.texts_to_sequences(x_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_text = tokenizer.texts_to_sequences(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = tokenizer.texts_to_sequences(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 87775\n",
      "Longest comment size: 995\n",
      "Average comment size: 105.61196033107151\n",
      "Stdev of comment size: 102.15050913314423\n",
      "Max comment size: 412\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_index)\n",
    "print('Vocab size: {}'.format(vocab_size))\n",
    "longest = max(len(seq) for seq in X_text)\n",
    "print(\"Longest comment size: {}\".format(longest))\n",
    "average = np.mean([len(seq) for seq in X_text])\n",
    "print(\"Average comment size: {}\".format(average))\n",
    "stdev = np.std([len(seq) for seq in X_text])\n",
    "print(\"Stdev of comment size: {}\".format(stdev))\n",
    "max_len = int(average + stdev * 3)\n",
    "print('Max comment size: {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_post_x_train = pad_sequences(x_train_text, maxlen=max_len, padding='post', truncating='post')\n",
    "processed_post_x_test = pad_sequences(x_test_text, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_x_train = pad_sequences(x_train_text, maxlen=max_len)\n",
    "processed_x_test = pad_sequences(x_test_text, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pre_x_train = pad_sequences(x_train_text, maxlen=max_len)\n",
    "processed_pre_x_test = pad_sequences(x_test_text, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (128745, 412)\n",
      "x_test shape: (32187, 412)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', processed_x_train.shape)\n",
    "print('x_test shape:', processed_x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "k = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        k += 1\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        #self.init = initializations.get('glorot_uniform')\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
    "\n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "    #print weigthted_input.shape\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    review_input = Input(shape=(max_len,), dtype='int32')\n",
    "    review_input_post = Input(shape=(max_len,), dtype='int32')\n",
    "    mnr_input = Input(shape=(1,), dtype='float32')  # Add MNR as a numeric input\n",
    "    pr_input = Input(shape=(1,), dtype='float32')   # Add PR as a numeric input\n",
    "    rl_input = Input(shape=(1,), dtype='float32')   # Add RL as a numeric input\n",
    "    rd_input = Input(shape=(1,), dtype='float32')   # Add RD as a numeric input\n",
    "    mcs_input = Input(shape=(1,), dtype='float32')  # Add MCS as a numeric input\n",
    "    rating = Input(shape=(1,), dtype='float32')  # Add MCS as a numeric input\n",
    "\n",
    "    x1 = Embedding(vocab_size + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(review_input)\n",
    "    x1 = Bidirectional(LSTM(60, return_sequences=True))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Attention(max_len)(x1)\n",
    "\n",
    "    x2 = Embedding(vocab_size + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(review_input_post)\n",
    "    x2 = Bidirectional(LSTM(60, return_sequences=True))(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    x2 = Attention(max_len)(x2)\n",
    "\n",
    "    x = concatenate([x1, x2, mnr_input, pr_input, rl_input, rd_input, mcs_input,rating])\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x= Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[review_input, review_input_post, mnr_input, pr_input, rl_input, rd_input, mcs_input,rating], outputs=preds)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 412)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 412)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 412, 100)     8777600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 412, 100)     8777600     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 412, 120)     77280       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 412, 120)     77280       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 412, 120)     0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 412, 120)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 120)          532         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 120)          532         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 246)          0           attention[0][0]                  \n",
      "                                                                 attention_1[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           12350       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 50)           200         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            51          batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 17,723,425\n",
      "Trainable params: 17,723,325\n",
      "Non-trainable params: 100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maximum_review_per_day_for_user</th>\n",
       "      <th>percent_postive_reviews_by_user</th>\n",
       "      <th>max_user_review_length</th>\n",
       "      <th>avg_user_rating_deviation_per_product</th>\n",
       "      <th>max_cosine_similarity_to_user_reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130489</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>42.50000</td>\n",
       "      <td>0.152120</td>\n",
       "      <td>0.214467</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128304</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.837278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130650</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>43.50000</td>\n",
       "      <td>0.160822</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150573</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78317</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0.760401</td>\n",
       "      <td>0.100903</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123085</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>58.00000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45654</th>\n",
       "      <td>4</td>\n",
       "      <td>0.71875</td>\n",
       "      <td>110.71875</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.375990</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51873</th>\n",
       "      <td>5</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>119.60000</td>\n",
       "      <td>0.544865</td>\n",
       "      <td>0.420381</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151097</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97457</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.091378</td>\n",
       "      <td>0.296079</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128745 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        maximum_review_per_day_for_user  percent_postive_reviews_by_user  \\\n",
       "130489                                1                          1.00000   \n",
       "128304                                1                          0.00000   \n",
       "130650                                1                          1.00000   \n",
       "150573                                1                          1.00000   \n",
       "78317                                 2                          1.00000   \n",
       "...                                 ...                              ...   \n",
       "123085                                1                          1.00000   \n",
       "45654                                 4                          0.71875   \n",
       "51873                                 5                          0.80000   \n",
       "151097                                1                          0.00000   \n",
       "97457                                 1                          1.00000   \n",
       "\n",
       "        max_user_review_length  avg_user_rating_deviation_per_product  \\\n",
       "130489                42.50000                               0.152120   \n",
       "128304                 9.00000                               1.837278   \n",
       "130650                43.50000                               0.160822   \n",
       "150573                25.00000                               0.869048   \n",
       "78317                 38.50000                               0.760401   \n",
       "...                        ...                                    ...   \n",
       "123085                58.00000                               1.120000   \n",
       "45654                110.71875                               0.595595   \n",
       "51873                119.60000                               0.544865   \n",
       "151097                34.00000                               1.384615   \n",
       "97457                 10.00000                               0.091378   \n",
       "\n",
       "        max_cosine_similarity_to_user_reviews  rating  \n",
       "130489                               0.214467       4  \n",
       "128304                               0.000000       2  \n",
       "130650                               0.117143       4  \n",
       "150573                               0.000000       5  \n",
       "78317                                0.100903       4  \n",
       "...                                       ...     ...  \n",
       "123085                               0.000000       5  \n",
       "45654                                0.375990       3  \n",
       "51873                                0.420381       4  \n",
       "151097                               0.000000       1  \n",
       "97457                                0.296079       4  \n",
       "\n",
       "[128745 rows x 6 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4024/4024 [==============================] - 463s 112ms/step - loss: 0.5451 - accuracy: 0.7293 - val_loss: 0.4809 - val_accuracy: 0.7732\n",
      "Epoch 2/10\n",
      "4024/4024 [==============================] - 436s 108ms/step - loss: 0.4452 - accuracy: 0.7961 - val_loss: 0.4800 - val_accuracy: 0.7630\n",
      "Epoch 3/10\n",
      "4024/4024 [==============================] - 433s 108ms/step - loss: 0.3900 - accuracy: 0.8264 - val_loss: 0.5352 - val_accuracy: 0.7530\n",
      "Epoch 4/10\n",
      "4024/4024 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8476"
     ]
    }
   ],
   "source": [
    "history = model.fit([processed_x_train,processed_pre_x_train,x_train_numeric['maximum_review_per_day_for_user'],x_train_numeric['percent_postive_reviews_by_user'],x_train_numeric['max_user_review_length'],x_train_numeric['avg_user_rating_deviation_per_product'],x_train_numeric['max_cosine_similarity_to_user_reviews'],x_train_numeric['rating']],y_train, validation_data=([processed_x_test,processed_pre_x_test,x_test_numeric['maximum_review_per_day_for_user'],x_test_numeric['percent_postive_reviews_by_user'],x_test_numeric['max_user_review_length'],x_test_numeric['avg_user_rating_deviation_per_product'],x_test_numeric['max_cosine_similarity_to_user_reviews'],x_test_numeric['rating']],y_test), epochs=10,batch_size=32,callbacks=[early_stopping_monitor],verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
