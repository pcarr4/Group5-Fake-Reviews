# -*- coding: utf-8 -*-
"""SWM New Dataset Balanced.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LGhVGrxV4VprmA6dCGFd_Yu5XOJEbOAK
"""

from google.colab import drive

drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/reviewContent+metadata.csv

import numpy as np
import pandas as pd
import itertools

dataset=pd.read_csv("/content/reviewContent+metadataBalanced.csv", encoding="ISO-8859-1",on_bad_lines='skip')
dataset=dataset.astype(str)

dataset.shape
dataset.head(10)

labels=dataset.label
labels.head(10)

dataset.replace(to_replace="0",value="FAKE",inplace=True)
dataset.replace(to_replace="1",value="REAL",inplace=True)

labels=dataset.label
labels.head(10)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(dataset['text_'],labels,test_size=0.2,random_state=10)

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer=TfidfVectorizer(stop_words='english',max_df=0.7)
tfidf_train=tfidf_vectorizer.fit_transform(x_train)
tfidf_test=tfidf_vectorizer.transform(x_test)

from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
pac=PassiveAggressiveClassifier(max_iter=50)
pac.fit(tfidf_train,y_train)

y_pred=pac.predict(tfidf_test)
score=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score*100,2)}%')

confusion_matrix(y_test,y_pred,labels=['FAKE','REAL'])

from matplotlib import pyplot as plt
pos=0
neg=0
for score in dataset['label']:
  if score == "REAL":
    pos+=1
  elif score == "FAKE":
    neg+=1

values=[int(pos),int(neg)]
label = ['Positive Reviews','Negative Reviews']

fig = plt.figure(figsize=(10,7))
plt.pie(values,labels=label)
print(pos,"POSITIVE REVIEW")
print(neg,"NEGATIVE REVIEW")

from sklearn.metrics import classification_report

print(classification_report(y_test,y_pred))

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt

plt.hist(dataset['rating'], bins=5, alpha=0.5, label='Fake Reviews', color='red')
plt.hist(dataset['rating'], bins=5, alpha=0.5, label='Real Reviews', color='blue')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.legend(loc='best')
plt.title('Distribution of Ratings for Fake and Real Reviews')
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

start_prod_id = 0  # Change this to your desired starting product ID
end_prod_id = 50   # Change this to your desired ending product ID


dataset['prod_id'] = pd.to_numeric(dataset['prod_id'], errors='coerce')

# Filter the dataset for the specified product ID range
subset_data = dataset[(dataset['prod_id'] >= start_prod_id) & (dataset['prod_id'] <= end_prod_id)]

# Create a bar plot
plt.figure(figsize=(12, 6))
sns.countplot(data=subset_data, x='prod_id', hue='label', palette='Set2')
plt.xlabel('Product ID')
plt.ylabel('Count of customers')
plt.legend(title='Review Type', loc='upper right')
plt.title(f'Distribution of Fake and Real Reviews for Product IDs {start_prod_id} to {end_prod_id}')
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability

plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

start_prod_id = 0  # Change this to your desired starting product ID
end_prod_id = 50   # Change this to your desired ending product ID

# Filter the dataset for the specified product ID range
subset_data = dataset[(dataset['prod_id'] >= start_prod_id) & (dataset['prod_id'] <= end_prod_id)]

# Create a bar plot
plt.figure(figsize=(12, 6))
sns.scatterplot(data=subset_data, x='prod_id', y='rating', hue='label', palette='Set2', alpha=0.6, s=100)
plt.xlabel('Product ID')
plt.ylabel('Rating')
plt.legend(title='Review Type')
plt.title('Scatter Plot of Product ID vs. Rating with Fake and Real Reviews')

plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

fake_reviews = dataset[dataset['label'] == -1]
real_reviews = dataset[dataset['label'] == 1]

dataset['prod_id'] = pd.to_numeric(dataset['prod_id'], errors='coerce')
dataset['label'] = pd.to_numeric(dataset['label'], errors='coerce')
dataset['rating'] = pd.to_numeric(dataset['rating'], errors='coerce')

# Group data by 'prod_id' and calculate the average rating for fake and real reviews
avg_ratings = dataset.groupby(['prod_id', 'label'])['rating'].mean().reset_index()

# Create a pivot table for the heatmap
heatmap_data = avg_ratings.pivot(index='prod_id', columns='label', values='rating')

# Create a heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(heatmap_data, cmap='coolwarm', annot=True, fmt=".2f")
plt.xlabel('Review Type')
plt.ylabel('Product ID')
plt.title('Average Ratings by Product ID for Fake and Real Reviews')
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Create a count plot
plt.figure(figsize=(12, 6))
sns.countplot(data=dataset, x='prod_id', hue='label', palette='Set2')
plt.xlabel('prod_id')
plt.ylabel('Count')
plt.legend(title='Review Type', loc='upper right')
plt.title('Distribution of Fake and Real Reviews by Product ID')
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability

plt.show()

